浮点数从十进制到二进制中为啥要采用×2取整的方式？
以及float 和double 类型的的精度是如何确定的？

先来看几个式子。
0.5*2=1 - ->0.5 = 1*2exp(-1);
若二进制小数的第一位为-1位，则二进制0.1- ->1*2exp(-1);

0.6*2=1.2- ->0.6= (1+0.2)*2exp(-1)=1*2exp(-1) + 0.2*2exp(-1)；

0.2*2*2*2=1.6- ->0.2=(1+0.6)*2exp(-3)=1*2exp(-3)+0.6*2exp(-3);

0.2*2exp(-1)=(1+0.6)*2exp(-3)*2exp(-1)=1*2exp(-4)+0.6*2exp(-4);

0.6=1*2exp(-1)+1*2exp(-4)+0.6*2exp(-4)；

看出什么东西了没？
我在将十进制的小数分成很多1*2exp(*)项之和，并且每后一项比前一项要小，很显然给的二进制位数越多我能保存的数就越靠近真实的数。

下面再来讨论什么是精度？
我是这样去理解的，如果两个数的差小于某一个数时，当这个数越小，那么这两个数他们之间越接近。那么计算机在用户输入一个浮点数时，由于位数有限，真正保存到计算机上的数与用户输入的数之间的差值小于某一给定的
值，相当于计算机用精度无限逼近真实数，也就是计算机保存的数与我实际输入的数的差的绝对值，这就是我对计算机中精度的理解。


下面看看计算机中是如何存储浮点数的。
十进制数12.123转换成二进制整数部分是1100，小数采取上面的方法不断地去接近进真实数近似为00111101111110111110011101101100...
假设一共给23位存小数，那么0.123分成很多1*2exp(*)项之和这些项从大到小排列，当加到某一项小于1*2exp(-23)时,前面的项都可以在23位上表示，那么计算机记录的数就是前面的这些项的和，计算机存入的数与真实的数
误差小于1*2exp(-23)=0.000 0001192...
